import requests
import pandas as pd
from urllib.parse import unquote
import time

# 1. API ì„¤ì •
url = 'http://www.safetydata.go.kr/V2/api/DSSP-IF-00117'
service_key = unquote('8X1JX1NIW9DT3BE7')
rows_per_page = 1000  # ì„œë²„ì— ë¬´ë¦¬ê°€ ê°€ì§€ ì•ŠëŠ” ì„ ì—ì„œ ìµœëŒ€ì¹˜ ì„¤ì •

all_data_list = []

# 2. ì „ì²´ ê°œìˆ˜ ë‹¤ì‹œ í™•ì¸
params = {
    'serviceKey': service_key,
    'returnType': 'json',
    'pageNo': '1',
    'numOfRows': '1'
}

try:
    response = requests.get(url, params=params)
    total_count = response.json().get('totalCount', 0)
    total_pages = (total_count // rows_per_page) + 1
    print(f"ğŸš€ ì „ì²´ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì‹œì‘: ì´ {total_count}ê±´ (ì˜ˆìƒ í˜¸ì¶œ: {total_pages}íšŒ)")

    # 3. ì „ì²´ í˜ì´ì§€ ë£¨í”„
    for page in range(1, total_pages + 1):
        params['pageNo'] = str(page)
        params['numOfRows'] = str(rows_per_page)
        
        res = requests.get(url, params=params)
        if res.status_code == 200:
            items = res.json().get('body', [])
            all_data_list.extend(items) # ë¦¬ìŠ¤íŠ¸ì— í†µì§¸ë¡œ ì¶”ê°€
            print(f"ğŸ“¥ ë°ì´í„° ìˆ˜ì§‘ ì¤‘... {page}/{total_pages} ì™„ë£Œ (ëˆ„ì : {len(all_data_list)}ê±´)")
        
        # ì„œë²„ ë§¤ë„ˆ: ê³¼ë„í•œ íŠ¸ë˜í”½ ë°©ì§€ë¥¼ ìœ„í•´ ì•„ì£¼ ì ê¹ ì‰½ë‹ˆë‹¤.
        time.sleep(0.1)

    # 4. CSV íŒŒì¼ë¡œ ì €ì¥
    if all_data_list:
        df = pd.DataFrame(all_data_list)
        # ì—‘ì…€ì—ì„œ í•œê¸€ì´ ê¹¨ì§€ì§€ ì•Šë„ë¡ utf-8-sig ì¸ì½”ë”© ì‚¬ìš©
        df.to_csv("all_flood_trace_data.csv", index=False, encoding='utf-8-sig')
        print(f"\nâœ… [ì„±ê³µ] ì „ì²´ {len(all_data_list)}ê±´ ë°ì´í„°ë¥¼ 'all_flood_trace_data.csv'ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
    else:
        print("\nâŒ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

except Exception as e:
    print(f"ì—ëŸ¬ ë°œìƒ: {e}")